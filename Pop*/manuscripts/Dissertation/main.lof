\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A visual representation of a possible probability distribution over global song structures composed of verses (V), choruses (C), intros (I), outros (O), and bridges (B).\relax }}{14}{figure.caption.4}
\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual representation of a possible probability distribution over the number of segments per song. Red corresponds to high probability, blue to low.\relax }}{15}{figure.caption.5}
\contentsline {figure}{\numberline {2.3}{\ignorespaces A visual representation of a possible single-order Markov transition matrix for segment types. Red corresponds to high probability, blue to low. The results largely agree with intuition. For example, songs generally start with an intro and occasionally with a verse; songs generally end with an outro and occasionally a chorus; and segments of the same type do not generally follow one another.\relax }}{16}{figure.caption.6}
\contentsline {figure}{\numberline {2.4}{\ignorespaces A visual representation of an empirically derived probability distribution over song segment lengths, conditioned on segment type. Red corresponds to high probability, blue to low. The results largely agree with intuition: intros, outros, and interludes tend to be shorter; verses, bridges and choruses tend to be longer.\relax }}{18}{figure.caption.7}
\contentsline {figure}{\numberline {2.5}{\ignorespaces A visual representation of an empirically derived probability distribution over song segment rhyme structures conditioned on segment length. Red corresponds to high probability, blue to low.\relax }}{19}{figure.caption.8}
\contentsline {figure}{\numberline {2.6}{\ignorespaces A subsection of a visual representation of an empirically derived single-order Markov transition matrix for harmonic chord sequences for chorus segments. Red corresponds to high probability, blue to low. As expected for songs normalized to the key of C major, there is high probability that the song starts on a C major chord. \relax }}{21}{figure.caption.10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces A visual representation of an empirically derived single-order Markov model for melodic rhythm durations for verse segments in 4/4. Red corresponds to high probability, blue to low.\relax }}{23}{figure.caption.12}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Three measures of a sample composition generated using the HBPL framework. The full composition and others can be found online at \url {popstar.cs.byu.edu}.\relax }}{24}{figure.caption.14}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \textit {A 3rd-Order word-level Markov model.} The model has been trained on the phrases ``once I saw a bear with hair'' and ``once I saw a cat with hair''. Since each word is a single syllable, this example also represents a syllable-level model. Each element in this model is a 3-length sequence of tokens and transitions are between sequences that overlap by all but one token. Note that though an element sequence from this model will have length 5, the generated token sequence will have length 7 (i.e., element sequence length + order - 1).\relax }}{33}{figure.caption.19}
\contentsline {figure}{\numberline {3.2}{\ignorespaces \textit {A 3rd-order NHMM of length 4.} This model is built from the Markov model in Figure\nobreakspace {}\ref {fig:higher_order_markov} and generates sequences of length 6. States marked with a white `X' are pruned due to the length constraint (i.e., transitions through these states do not result in element sequences of length 4). States marked with a gray `X' are pruned due to the addition of the $C_3$ POS constraint. This constraint is an example of a floating constraint in that the POS constraint is effectively satisfied by any satisfying token appearing at sequence positions 3, 4, or 5. States marked with a black `X' are pruned due to the further addition of the $C_4$ rhyme constraint. The $C_4$ constraint is an example of a dynamic constraint in that the token constraint at sequence position 6 effectively depends on the token at sequence position\nobreakspace {}4. Grey transitions represent transition probabilities that are zeroed as a result of applied constraints.\relax }}{34}{figure.caption.20}
\contentsline {figure}{\numberline {3.3}{\ignorespaces \textit {Floating syntax constraints}. Shown are two 10-syllable phrases (representing the overlap of two states in a 9th-order NHMM) each with its syllable-level POS template (per the Stanford CoreNLP Toolkit). The tree represents a floating word-level POS template constraint. Each path through the tree represents a POS sequence that is valid per the constraint. Each phrase (representing a Markov transition) is either kept or pruned according to whether or not its syllable-level template (when identical consecutive tags are merged) has a valid path through the tree. This is a floating constraint because the POS tags from the constraint are not imposed on specific positions in the syllable-level template. Thus despite having different syllable-level POS templates, both phrases satisfy the constraint via the same path (grey).\relax }}{40}{figure.caption.25}
\contentsline {figure}{\numberline {3.4}{\ignorespaces \textit {Qualitative evaluation.} Results of 470 survey responses rating human- and computer-generated solutions to the DBTB problem. Error bars represent standard error.\relax }}{42}{figure.caption.27}
\contentsline {figure}{\numberline {3.5}{\ignorespaces \textit {Haikus}. These haikus are generated from syllable-level NHMMs with floating constraints. (Left) An \textit {objet trouv\'e} found using a 5th-order NHMM with a \textit {nature}-themed floating semantic constraint. (Right) An original haiku generated from a 4th-order NHMM with floating word-level POS template constraints and a \textit {beauty/earth}-themed floating semantic constraint.\relax }}{44}{figure.caption.28}
\contentsline {figure}{\numberline {3.6}{\ignorespaces \textit {Prosodic rhythm for lyrics}. Given the lyric ``No more monkeys jumping on the bed!'', we used a 4th-order NHMM over rhythm tokens to generate prosodic rhythms like those shown here. Stressed syllables are \textbf {bold} and notes in emphasized rhythmic positions are in parentheses.\relax }}{44}{figure.caption.29}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textit {Traditional Smith-Waterman Alignment Example}. Shown is an example of DNA alignment using the Smith-Waterman algorithm. The highest scoring alignment is derived starting from the highest scoring cell in the alignment matrix and then backtracking along the path taken to arrive at that cell until the path reaches a cell with a score of 0. The alignment suggests which DNA bases from each DNA sequence are matching. We use an analogous method to find matching sequence events in music. Image courtesy of Wikimedia Commons.\relax }}{49}{figure.caption.30}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \textit {Example of a music sequence event}. Musical sequences are non-discrete and thus events must be sampled. Table\nobreakspace {}\ref {tab:features} describes the features and feature values for the event sampled at the dotted red line.\relax }}{50}{figure.caption.32}
\contentsline {figure}{\numberline {4.3}{\ignorespaces \textit {Finding pitch structure via sequence alignment}. Representing the song \textit {Twinkle, Twinkle, Little Star} as a sequence of discrete events, we align the song against itself using a multiple Smith-Waterman alignment and a pitch-specific pairwise scoring function. The longer red diagonal represents the repetition of pitch between the two choruses in the song whereas the smaller diagonal represents repetition of pitch within the bridge section. Weights for the pairwise scoring function are learned via genetic algorithm (see Figure\nobreakspace {}\ref {fig:learning_weights}). In this example, 27 generations were required to find weights which maximize the fitness function (F-score).\relax }}{53}{figure.caption.33}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \textit {Learning weights for the pitch scoring function}. As scoring function weights are adjusted via the GA, different alignments result. We use a multiple Smith-Waterman alignment approach to find all local alignments that result in a score above a threshold $\tau $ (also determined by the GA). As weightings are found that more accurately align (labeled) pitch repetitions, the F-score increases. Shown is the alignment of the song \textit {Twinkle, Twinkle, Little Star}.\relax }}{53}{figure.caption.34}
\contentsline {figure}{\numberline {4.5}{\ignorespaces \textit {Structure Detection}. For each viewpoint (i.e., column), the same scoring function weights were used. This suggests a common scoring function can be used to find viewpoint-specific structure across different songs. The \textit {Chorus} and \textit {Verse} columns use scoring functions that are a composite of the four primitive viewpoint scoring functions. Using the GA approach for finding alignment weights for each viewpoint, we can extract the structure for each viewpoint for a given song. These structural representations can then be used for subsequent analyses including classification and generation. For each viewpoint, $v$, $F_{1}$ is $F_{1}(\Gamma ^*_v)$. For each song, $F_{1}$ is the average $F_{1}(\Gamma ^*_v)$ across alignments for all viewpoints $v$ for that song only.\relax }}{60}{figure.caption.42}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces \textit {A {\sc Relational} automaton}. The result of Algorithm\nobreakspace {}\ref {alg:matching} on inputs $n=4$; $\mathcal {M}=\{(X_1,X_4,\rho \}$ (where $\rho $ represents the set of rhyming word pairs); $I=\{$\textit {Mary}, \textit {Clay}$\}$; and $T$ derived from the non-zero transitions represented in the Markov model shown in Figure\nobreakspace {}\ref {fig:markov}.\relax }}{68}{figure.caption.44}
\contentsline {figure}{\numberline {5.2}{\ignorespaces \textit {A Markov model.}\relax }}{69}{figure.caption.45}
\contentsline {figure}{\numberline {5.3}{\ignorespaces \textit {A ``state-sensitive'' pseudo-Markov model.} This is the model $M'$ built in Algorithm\nobreakspace {}\ref {alg:nhmm} given as inputs the automaton in Figure\nobreakspace {}\ref {fig:DFA}, the Markov model in Figure\nobreakspace {}\ref {fig:markov}, an empty unary constraint set, and a length $n=4$. This is a ``pseudo''-Markov model because, given this approach, probabilities must remain unnormalized for proper construction of the NHMM.\relax }}{73}{figure.caption.46}
\contentsline {figure}{\numberline {5.4}{\ignorespaces \textit {Amortized Sample Time By Sequences Generated}. Shown are average amortized sample times per sequence (belonging to the set $\{aa+b+\}$ of fixed length 100) when sampling using a NHMM (blue) and factor graph (orange). The NHMM has a longer build time but shorter sample time per sequence meaning that as the number of sequences increases, the NHMM has a lower amortized sample time than the factor graph.\relax }}{73}{figure.caption.47}
\contentsline {figure}{\numberline {5.5}{\ignorespaces \textit {Sample Time By Length}. Shown are average sample times for the NHMM (blue) and factor graph (orange) from sampling 100,000 sequences belonging to the set $\{aa+b+\}$. Both sample times increase linearly with the sequence length. Though the sample time per sequence is always lower for the NHMM, the NHMM build time also increases with sequence length resulting in a lower \emph {amortized} sample time (dotted lines) for factor graphs as the sequence length increases.\relax }}{74}{figure.caption.48}
\contentsline {figure}{\numberline {5.6}{\ignorespaces \textit {Inferring Relational Constraints}. Relational constraint sets are inferred from real data using multiple-Smith-Waterman sequence alignment. Shown are the structural patterns inferred for the chord, pitch, rhythm, and lyric sequences in \emph {Twinkle, Twinkle, Little Star}.\relax }}{75}{figure.caption.49}
\contentsline {figure}{\numberline {5.7}{\ignorespaces \textit {Horizontal and Vertical Structure}. Shown are four parallel sequences (chords, pitches, rhythms, and lyrics) that exhibit both \emph {horizontal} structure---each fully satisfies Markovian constraints---and \emph {vertical structure}---each fully satisfies binary relational constraints, frequently in the same sequence positions as with relational constraints in other sequences. Boxes of the same color are used to illustrate subsequences which position-by-position are constrained via binary relational constraints to be equivalent. Dark red boxes reflect binary relational rhyming constraints. Not labeled is the pattern of rhythmic repetition every 2 measures.\relax }}{75}{figure.caption.50}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces \textit {Pop* Overview}. A high-level depiction of the process by which Pop* composes new music. The system is inspired by social media posts that appeal to its aesthetic. This inspiration guides the training of generative models through a targeted subselection of available lyrics and lead sheets for training. Generated artefacts are output on condition that they pass an intention-driven self-evaluation.\relax }}{91}{figure.caption.51}
\contentsline {figure}{\numberline {6.2}{\ignorespaces \textit {NHMM for Binary Constraints}. Shown is a NHMM. Each column represents a position in the sequence to be generated. Transitions between columns are derived from the transition probabilities in the NHMM's underlying Markov model. This NHMM is built from a DFA that implements the binary constraint requiring the first and fourth positions of a sequence rhyme. The DFA adds automaton state sensitivity to the Markov states as detailed in \cite {bodily2018relational}.\relax }}{94}{figure.caption.52}
\contentsline {figure}{\numberline {6.3}{\ignorespaces \textit {Graphical HBPL model}. This graphical model reflects the dependencies between subconcept models in Pop*'s HBPL model for lyrical music composition.\relax }}{98}{figure.caption.53}
\contentsline {figure}{\numberline {6.4}{\ignorespaces \textit {Learning Structure}. For each novel composition, Pop* chooses an existing song (in this case \textit {Twinkle, Twinkle, Little Star}) after which to model structural patterns of repetition. Pop* uses a multi-Smith-Waterman alignment with a genetically trained scoring function to find structure in (from left to right) chords, pitch, rhythm, and lyrics.\relax }}{101}{figure.caption.55}
\contentsline {figure}{\numberline {6.5}{\ignorespaces \textit {External Artifact Representation}. Pop*'s creative process results essentially in a pop lead sheet (colored boxes highlight structural patterns of repetition). With regards to this composition, Pop* wrote: ``I spend a lot of time thinking and reading about \textbf {being in love}, and I read this tweet from my friend Joel Alcaraz posted Tuesday, June 12, 2018 at 6:34 PM: `\textit {It's interesting being in love with a person, I told Ashley my love for him is like dancing on the edge of a cliff always feeling a sense of trepidation before the grand leap into his world. But in the end no matter my fear I make a leap of faith. Is that what love is?}' It got me thinking about \textbf {fear} and \textbf {love} themes and I couldn't help but write this song: `\textit {And I think I am just a lie `Cause when you find yourself behind And I think I am just a lie}'. At the beginning it was \textbf {fear} and \textbf {love}, however it really wound up with more of a \textbf {deception} and \textbf {negative} emotion theme. I hope that you like it.'' This composition rated highest overall in an external evaluation of 12 randomly selected Pop* compositions.\relax }}{106}{figure.caption.56}
\addvspace {10\p@ }
