\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ix}{toclistings.1}}
\citation{bodily2018relational}
\citation{Fast2016}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xvii}{toclistings.2}}
\@writefile{toc}{\contentsline {chapter}{List of Listings}{xix}{toclistings.3}}
\citation{colton2012computational}
\citation{Jennings2010DevelopingIntelligence}
\citation{Bodily2018MusicalFuture}
\citation{Jaques2016,roy2016enforcing}
\citation{Nunes2014}
\citation{collins2017computer}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{pachet2011finite}
\citation{papadopoulos2015exact}
\citation{perez2017mdds}
\citation{Barbieri2012MarkovStyle}
\citation{pachet2011finite}
\citation{papadopoulos2015exact}
\citation{roy2016enforcing}
\citation{Jaques2016}
\citation{perez2017mdds}
\citation{collins2017computer}
\citation{collins2017computer}
\citation{meredith2002algorithms}
\citation{collins2017computer}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Survey of Existing Approaches to Structured Music Generation\relax }}{4}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:systems}{{1.1}{4}{Survey of Existing Approaches to Structured Music Generation\relax }{table.caption.1}{}}
\citation{colton2015stakeholder}
\citation{Jordanous2014}
\citation{englemann1974distar}
\citation{lake2015human}
\citation{lake2015human}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Computational Creativity via Human-Level Concept Learning}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{7}{section.2.1}}
\citation{pachet2011finite}
\citation{pachet2011finite}
\newlabel{eq:1}{{2.1}{8}{Introduction}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Modeling with HBPL}{8}{section.2.2}}
\citation{lake2015human}
\citation{bodily2017Mume}
\citation{bodily2017Mume}
\citation{bodily2017Mume}
\citation{bodily2017Mume}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Composition}{11}{subsection.2.2.1}}
\citation{bay2017ICCC}
\@writefile{toc}{\contentsline {subsubsection}{Intention, $P(\nu |\iota )$}{12}{section*.2}}
\citation{morris2012soup}
\@writefile{toc}{\contentsline {subsubsection}{Structure, $P(\tau |\nu )$}{13}{section*.3}}
\citation{pachet2011finite}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  A visual representation of a possible probability distribution over global song structures composed of verses (V), choruses (C), intros (I), outros (O), and bridges (B).\relax }}{14}{figure.caption.4}}
\newlabel{fig:global_structure}{{2.1}{14}{A visual representation of a possible probability distribution over global song structures composed of verses (V), choruses (C), intros (I), outros (O), and bridges (B).\relax }{figure.caption.4}{}}
\citation{steedman1984generative}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  A visual representation of a possible probability distribution over the number of segments per song. Red corresponds to high probability, blue to low.\relax }}{15}{figure.caption.5}}
\newlabel{fig:segment_count_per_song}{{2.2}{15}{A visual representation of a possible probability distribution over the number of segments per song. Red corresponds to high probability, blue to low.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  A visual representation of a possible single-order Markov transition matrix for segment types. Red corresponds to high probability, blue to low. The results largely agree with intuition. For example, songs generally start with an intro and occasionally with a verse; songs generally end with an outro and occasionally a chorus; and segments of the same type do not generally follow one another.\relax }}{16}{figure.caption.6}}
\newlabel{fig:segment_transitions}{{2.3}{16}{A visual representation of a possible single-order Markov transition matrix for segment types. Red corresponds to high probability, blue to low. The results largely agree with intuition. For example, songs generally start with an intro and occasionally with a verse; songs generally end with an outro and occasionally a chorus; and segments of the same type do not generally follow one another.\relax }{figure.caption.6}{}}
\citation{meyer2008emotion}
\citation{meyer2008emotion}
\citation{pachet2014imitative,barbieri2012markov}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  A visual representation of an empirically derived probability distribution over song segment lengths, conditioned on segment type. Red corresponds to high probability, blue to low. The results largely agree with intuition: intros, outros, and interludes tend to be shorter; verses, bridges and choruses tend to be longer.\relax }}{18}{figure.caption.7}}
\newlabel{fig:measure_count_by_segment}{{2.4}{18}{A visual representation of an empirically derived probability distribution over song segment lengths, conditioned on segment type. Red corresponds to high probability, blue to low. The results largely agree with intuition: intros, outros, and interludes tend to be shorter; verses, bridges and choruses tend to be longer.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  A visual representation of an empirically derived probability distribution over song segment rhyme structures conditioned on segment length. Red corresponds to high probability, blue to low.\relax }}{19}{figure.caption.8}}
\newlabel{fig:segment_structure}{{2.5}{19}{A visual representation of an empirically derived probability distribution over song segment rhyme structures conditioned on segment length. Red corresponds to high probability, blue to low.\relax }{figure.caption.8}{}}
\citation{hirjee2010using}
\citation{hirjee2010using}
\citation{pachet2014imitative}
\@writefile{toc}{\contentsline {subsubsection}{Harmony, $P(\eta |\nu ,\tau )$}{20}{section*.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  A subsection of a visual representation of an empirically derived single-order Markov transition matrix for harmonic chord sequences for chorus segments. Red corresponds to high probability, blue to low. As expected for songs normalized to the key of C major, there is high probability that the song starts on a C major chord. \relax }}{21}{figure.caption.10}}
\newlabel{fig:harmony}{{2.6}{21}{A subsection of a visual representation of an empirically derived single-order Markov transition matrix for harmonic chord sequences for chorus segments. Red corresponds to high probability, blue to low. As expected for songs normalized to the key of C major, there is high probability that the song starts on a C major chord. \relax }{figure.caption.10}{}}
\citation{bodily2017Mume}
\citation{bodily2017Mume}
\newlabel{model:distribution_model}{{2}{22}{Harmony, $P(\eta |\nu ,\tau )$}{Item.14}{}}
\newlabel{model:seg_model}{{4}{22}{Harmony, $P(\eta |\nu ,\tau )$}{Item.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{Melody, $P(\mu |\nu ,\tau ,\eta )$}{22}{section*.11}}
\citation{paris2013natural}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces  A visual representation of an empirically derived single-order Markov model for melodic rhythm durations for verse segments in 4/4. Red corresponds to high probability, blue to low.\relax }}{23}{figure.caption.12}}
\newlabel{fig:melody_rhythm}{{2.7}{23}{A visual representation of an empirically derived single-order Markov model for melodic rhythm durations for verse segments in 4/4. Red corresponds to high probability, blue to low.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Lyrics, $P(\lambda |\nu ,\tau ,\mu )$}{23}{section*.13}}
\citation{bay2017ICCC}
\citation{bay2017ICCC}
\citation{pachet2011finite}
\citation{pachet2011finite}
\citation{pachet2014imitative}
\citation{pachet2014imitative}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces  Three measures of a sample composition generated using the HBPL framework. The full composition and others can be found online at \url  {popstar.cs.byu.edu}.\relax }}{24}{figure.caption.14}}
\newlabel{fig:example_composition}{{2.8}{24}{Three measures of a sample composition generated using the HBPL framework. The full composition and others can be found online at \url {popstar.cs.byu.edu}.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{A Note on Constrained Markov Models}{25}{section*.15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Results and Discussion}{25}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Using the Joint as a Submodel}{25}{subsection.2.3.1}}
\citation{colton2008creativity}
\citation{lake2015human}
\citation{volioti2016mapping}
\@writefile{toc}{\contentsline {subsubsection}{Inspiration, $P(\iota )$}{26}{section*.16}}
\citation{lake2015human}
\citation{benetos2013automatic}
\@writefile{toc}{\contentsline {subsubsection}{Rendering, $P(\rho ^{m}|\iota ,\gamma )$}{27}{section*.17}}
\@writefile{toc}{\contentsline {subsubsection}{Implications for Recommendation Systems}{27}{section*.18}}
\citation{Ventura2016}
\citation{Ventura2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Fitness and Self-Evaluation}{28}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Big (Need for) Data}{28}{subsection.2.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Conclusion}{29}{section.2.4}}
\citation{Nunes2014}
\citation{pachet2011finite}
\citation{barbieri2012markov,roy2013enforcing,papadopoulos2015exact}
\citation{pachet2011finite}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Floating and Dynamic Constraints in Non-Homogeneous Markov Models}{30}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{30}{section.3.1}}
\citation{pesant2004regular,papadopoulos2014avoiding,papadopoulos2015exact,bodily2018relational}
\citation{bodily2018relational}
\citation{pachet2011finite}
\citation{papadopoulos2015exact}
\citation{pachet2011finite}
\citation{pachet2011finite}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Methods}{32}{section.3.2}}
\citation{pachet2011finite}
\citation{pachet2011finite}
\citation{pachet2011finite}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textit  {A 3rd-Order word-level Markov model.} The model has been trained on the phrases ``once I saw a bear with hair'' and ``once I saw a cat with hair''. Since each word is a single syllable, this example also represents a syllable-level model. Each element in this model is a 3-length sequence of tokens and transitions are between sequences that overlap by all but one token. Note that though an element sequence from this model will have length 5, the generated token sequence will have length 7 (i.e., element sequence length + order - 1).\relax }}{33}{figure.caption.19}}
\newlabel{fig:higher_order_markov}{{3.1}{33}{\textit {A 3rd-Order word-level Markov model.} The model has been trained on the phrases ``once I saw a bear with hair'' and ``once I saw a cat with hair''. Since each word is a single syllable, this example also represents a syllable-level model. Each element in this model is a 3-length sequence of tokens and transitions are between sequences that overlap by all but one token. Note that though an element sequence from this model will have length 5, the generated token sequence will have length 7 (i.e., element sequence length + order - 1).\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Optimizing NHMM Construction}{33}{section*.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \textit  {A 3rd-order NHMM of length 4.} This model is built from the Markov model in Figure\nobreakspace  {}\ref  {fig:higher_order_markov} and generates sequences of length 6. States marked with a white `X' are pruned due to the length constraint (i.e., transitions through these states do not result in element sequences of length 4). States marked with a gray `X' are pruned due to the addition of the $C_3$ POS constraint. This constraint is an example of a floating constraint in that the POS constraint is effectively satisfied by any satisfying token appearing at sequence positions 3, 4, or 5. States marked with a black `X' are pruned due to the further addition of the $C_4$ rhyme constraint. The $C_4$ constraint is an example of a dynamic constraint in that the token constraint at sequence position 6 effectively depends on the token at sequence position\nobreakspace  {}4. Grey transitions represent transition probabilities that are zeroed as a result of applied constraints.\relax }}{34}{figure.caption.20}}
\newlabel{fig:higher_order_nhmm}{{3.2}{34}{\textit {A 3rd-order NHMM of length 4.} This model is built from the Markov model in Figure~\ref {fig:higher_order_markov} and generates sequences of length 6. States marked with a white `X' are pruned due to the length constraint (i.e., transitions through these states do not result in element sequences of length 4). States marked with a gray `X' are pruned due to the addition of the $C_3$ POS constraint. This constraint is an example of a floating constraint in that the POS constraint is effectively satisfied by any satisfying token appearing at sequence positions 3, 4, or 5. States marked with a black `X' are pruned due to the further addition of the $C_4$ rhyme constraint. The $C_4$ constraint is an example of a dynamic constraint in that the token constraint at sequence position 6 effectively depends on the token at sequence position~4. Grey transitions represent transition probabilities that are zeroed as a result of applied constraints.\relax }{figure.caption.20}{}}
\citation{pachet2011finite}
\citation{barbieri2012markov}
\citation{barbieri2012markov}
\@writefile{toc}{\contentsline {subsubsection}{Floating Constraints}{35}{section*.22}}
\citation{barbieri2012markov}
\citation{barbieri2012markov}
\citation{Manning2014}
\newlabel{note1}{{1}{36}{}{Hfootnote.5}{}}
\citation{barbieri2012markov}
\citation{barbieri2012markov}
\citation{papadopoulos2014avoiding}
\citation{bodily2018relational}
\@writefile{toc}{\contentsline {subsubsection}{Dynamic Constraints}{37}{section*.23}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations of Dynamic Constraints}{37}{section*.24}}
\citation{ColtonExperimentsBrowsing}
\citation{jalongo1997using,pasiali2004use,robb2008randomized,towell1999motivating,kolb1996read}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Dynamic and Floating Constraint Examples}{38}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Dynamic Relational Constraints in Lyrics}{38}{subsection.3.3.1}}
\citation{davies2009385+}
\citation{Manning2014}
\citation{Walker2004}
\newlabel{mandatory_rhyme_constraint}{{4}{39}{Dynamic Relational Constraints in Lyrics}{Item.23}{}}
\newlabel{optional_rhyme_constraint}{{5}{39}{Dynamic Relational Constraints in Lyrics}{Item.24}{}}
\newlabel{POS_floating_constraint}{{6}{39}{Dynamic Relational Constraints in Lyrics}{Item.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \textit  {Floating syntax constraints}. Shown are two 10-syllable phrases (representing the overlap of two states in a 9th-order NHMM) each with its syllable-level POS template (per the Stanford CoreNLP Toolkit). The tree represents a floating word-level POS template constraint. Each path through the tree represents a POS sequence that is valid per the constraint. Each phrase (representing a Markov transition) is either kept or pruned according to whether or not its syllable-level template (when identical consecutive tags are merged) has a valid path through the tree. This is a floating constraint because the POS tags from the constraint are not imposed on specific positions in the syllable-level template. Thus despite having different syllable-level POS templates, both phrases satisfy the constraint via the same path (grey).\relax }}{40}{figure.caption.25}}
\newlabel{fig:syntax_tree}{{3.3}{40}{\textit {Floating syntax constraints}. Shown are two 10-syllable phrases (representing the overlap of two states in a 9th-order NHMM) each with its syllable-level POS template (per the Stanford CoreNLP Toolkit). The tree represents a floating word-level POS template constraint. Each path through the tree represents a POS sequence that is valid per the constraint. Each phrase (representing a Markov transition) is either kept or pruned according to whether or not its syllable-level template (when identical consecutive tags are merged) has a valid path through the tree. This is a floating constraint because the POS tags from the constraint are not imposed on specific positions in the syllable-level template. Thus despite having different syllable-level POS templates, both phrases satisfy the constraint via the same path (grey).\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces $d$-order NHMMs with Floating and Dynamic Constraints for Solving the DBTB Problem\relax }}{41}{table.caption.26}}
\newlabel{tab:model_summaries}{{3.1}{41}{$d$-order NHMMs with Floating and Dynamic Constraints for Solving the DBTB Problem\relax }{table.caption.26}{}}
\citation{davies2009385+}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \textit  {Qualitative evaluation.} Results of 470 survey responses rating human- and computer-generated solutions to the DBTB problem. Error bars represent standard error.\relax }}{42}{figure.caption.27}}
\newlabel{fig:results}{{3.4}{42}{\textit {Qualitative evaluation.} Results of 470 survey responses rating human- and computer-generated solutions to the DBTB problem. Error bars represent standard error.\relax }{figure.caption.27}{}}
\citation{mikolov2013distributed}
\citation{mikolov2013distributed}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Floating Semantic Constraints in Haiku}{43}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Floating Stress Constraints in Prosody}{43}{subsection.3.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Discussion}{43}{section.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces \textit  {Haikus}. These haikus are generated from syllable-level NHMMs with floating constraints. (Left) An \textit  {objet trouv\'e} found using a 5th-order NHMM with a \textit  {nature}-themed floating semantic constraint. (Right) An original haiku generated from a 4th-order NHMM with floating word-level POS template constraints and a \textit  {beauty/earth}-themed floating semantic constraint.\relax }}{44}{figure.caption.28}}
\newlabel{fig:haiku}{{3.5}{44}{\textit {Haikus}. These haikus are generated from syllable-level NHMMs with floating constraints. (Left) An \textit {objet trouv\'e} found using a 5th-order NHMM with a \textit {nature}-themed floating semantic constraint. (Right) An original haiku generated from a 4th-order NHMM with floating word-level POS template constraints and a \textit {beauty/earth}-themed floating semantic constraint.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces \textit  {Prosodic rhythm for lyrics}. Given the lyric ``No more monkeys jumping on the bed!'', we used a 4th-order NHMM over rhythm tokens to generate prosodic rhythms like those shown here. Stressed syllables are \textbf  {bold} and notes in emphasized rhythmic positions are in parentheses.\relax }}{44}{figure.caption.29}}
\newlabel{fig:monkeys}{{3.6}{44}{\textit {Prosodic rhythm for lyrics}. Given the lyric ``No more monkeys jumping on the bed!'', we used a 4th-order NHMM over rhythm tokens to generate prosodic rhythms like those shown here. Stressed syllables are \textbf {bold} and notes in emphasized rhythmic positions are in parentheses.\relax }{figure.caption.29}{}}
\citation{lake2015human}
\citation{englemann1974distar}
\citation{Nunes2014}
\citation{Bodily2017ComputationalLearning}
\citation{lecun2015deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Sequential Structure Inference Via Multiple Self-Alignment}{46}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{46}{section.4.1}}
\citation{meredith2002algorithms}
\citation{meredith2002algorithms}
\citation{collins2010comparative}
\citation{collins2010comparative}
\citation{collins2017computer}
\citation{collins2017computer}
\citation{lattner2015pseudo}
\citation{lattner2015pseudo}
\citation{lattner2015probabilistic}
\citation{lattner2015probabilistic}
\citation{conklin1995multiple}
\citation{needleman1970general}
\citation{smith1981identification}
\citation{dayhoff197822}
\citation{henikoff1992amino}
\citation{henikoff1992amino}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Methods}{48}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textit  {Traditional Smith-Waterman Alignment Example}. Shown is an example of DNA alignment using the Smith-Waterman algorithm. The highest scoring alignment is derived starting from the highest scoring cell in the alignment matrix and then backtracking along the path taken to arrive at that cell until the path reaches a cell with a score of 0. The alignment suggests which DNA bases from each DNA sequence are matching. We use an analogous method to find matching sequence events in music. Image courtesy of Wikimedia Commons.\relax }}{49}{figure.caption.30}}
\newlabel{fig:swexample}{{4.1}{49}{\textit {Traditional Smith-Waterman Alignment Example}. Shown is an example of DNA alignment using the Smith-Waterman algorithm. The highest scoring alignment is derived starting from the highest scoring cell in the alignment matrix and then backtracking along the path taken to arrive at that cell until the path reaches a cell with a score of 0. The alignment suggests which DNA bases from each DNA sequence are matching. We use an analogous method to find matching sequence events in music. Image courtesy of Wikimedia Commons.\relax }{figure.caption.30}{}}
\citation{needleman1970general}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces  Features for a music sequence event\relax }}{50}{table.caption.31}}
\newlabel{tab:features}{{4.1}{50}{Features for a music sequence event\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Multiple Smith-Waterman Self-Alignment}{50}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces \textit  {Example of a music sequence event}. Musical sequences are non-discrete and thus events must be sampled. Table\nobreakspace  {}\ref  {tab:features} describes the features and feature values for the event sampled at the dotted red line.\relax }}{50}{figure.caption.32}}
\newlabel{fig:music_sequence}{{4.2}{50}{\textit {Example of a music sequence event}. Musical sequences are non-discrete and thus events must be sampled. Table~\ref {tab:features} describes the features and feature values for the event sampled at the dotted red line.\relax }{figure.caption.32}{}}
\citation{smith1981identification}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Genetic Algorithm Parameters}{52}{subsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \textit  {Finding pitch structure via sequence alignment}. Representing the song \textit  {Twinkle, Twinkle, Little Star} as a sequence of discrete events, we align the song against itself using a multiple Smith-Waterman alignment and a pitch-specific pairwise scoring function. The longer red diagonal represents the repetition of pitch between the two choruses in the song whereas the smaller diagonal represents repetition of pitch within the bridge section. Weights for the pairwise scoring function are learned via genetic algorithm (see Figure\nobreakspace  {}\ref  {fig:learning_weights}). In this example, 27 generations were required to find weights which maximize the fitness function (F-score).\relax }}{53}{figure.caption.33}}
\newlabel{fig:alignment_example}{{4.3}{53}{\textit {Finding pitch structure via sequence alignment}. Representing the song \textit {Twinkle, Twinkle, Little Star} as a sequence of discrete events, we align the song against itself using a multiple Smith-Waterman alignment and a pitch-specific pairwise scoring function. The longer red diagonal represents the repetition of pitch between the two choruses in the song whereas the smaller diagonal represents repetition of pitch within the bridge section. Weights for the pairwise scoring function are learned via genetic algorithm (see Figure~\ref {fig:learning_weights}). In this example, 27 generations were required to find weights which maximize the fitness function (F-score).\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces \textit  {Learning weights for the pitch scoring function}. As scoring function weights are adjusted via the GA, different alignments result. We use a multiple Smith-Waterman alignment approach to find all local alignments that result in a score above a threshold $\tau $ (also determined by the GA). As weightings are found that more accurately align (labeled) pitch repetitions, the F-score increases. Shown is the alignment of the song \textit  {Twinkle, Twinkle, Little Star}.\relax }}{53}{figure.caption.34}}
\newlabel{fig:learning_weights}{{4.4}{53}{\textit {Learning weights for the pitch scoring function}. As scoring function weights are adjusted via the GA, different alignments result. We use a multiple Smith-Waterman alignment approach to find all local alignments that result in a score above a threshold $\tau $ (also determined by the GA). As weightings are found that more accurately align (labeled) pitch repetitions, the F-score increases. Shown is the alignment of the song \textit {Twinkle, Twinkle, Little Star}.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{Alignment Fitness Function}{54}{section*.35}}
\@writefile{toc}{\contentsline {subsubsection}{Alignment Scoring Functions}{55}{section*.36}}
\@writefile{toc}{\contentsline {subsubsection}{Harmony}{55}{section*.37}}
\@writefile{toc}{\contentsline {subsubsection}{Pitch}{56}{section*.38}}
\@writefile{toc}{\contentsline {subsubsection}{Rhythm}{57}{section*.39}}
\@writefile{toc}{\contentsline {subsubsection}{Lyrics}{57}{section*.40}}
\@writefile{toc}{\contentsline {subsubsection}{Chorus and Verse}{59}{section*.41}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Results and Discussion}{59}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces \textit  {Structure Detection}. For each viewpoint (i.e., column), the same scoring function weights were used. This suggests a common scoring function can be used to find viewpoint-specific structure across different songs. The \textit  {Chorus} and \textit  {Verse} columns use scoring functions that are a composite of the four primitive viewpoint scoring functions. Using the GA approach for finding alignment weights for each viewpoint, we can extract the structure for each viewpoint for a given song. These structural representations can then be used for subsequent analyses including classification and generation. For each viewpoint, $v$, $F_{1}$ is $F_{1}(\Gamma ^*_v)$. For each song, $F_{1}$ is the average $F_{1}(\Gamma ^*_v)$ across alignments for all viewpoints $v$ for that song only.\relax }}{60}{figure.caption.42}}
\newlabel{fig:song_v_viewpoint}{{4.5}{60}{\textit {Structure Detection}. For each viewpoint (i.e., column), the same scoring function weights were used. This suggests a common scoring function can be used to find viewpoint-specific structure across different songs. The \textit {Chorus} and \textit {Verse} columns use scoring functions that are a composite of the four primitive viewpoint scoring functions. Using the GA approach for finding alignment weights for each viewpoint, we can extract the structure for each viewpoint for a given song. These structural representations can then be used for subsequent analyses including classification and generation. For each viewpoint, $v$, $F_{1}$ is $F_{1}(\Gamma ^*_v)$. For each song, $F_{1}$ is the average $F_{1}(\Gamma ^*_v)$ across alignments for all viewpoints $v$ for that song only.\relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces \textit  {Generalizability}. (Top) Shown are average F-scores for training and test sets resulting from a 5-fold cross-validation on a 5-song dataset (1000 generations). (Bottom) Results aggregated from 2 of the 5 cross-folds in which the holdout song is of simpler composition (\textit  {Twinkle, Twinkle} and \textit  {Over the Rainbow}). Results suggest that even with limited training, generalization is possible, particularly when generalizing to compositions with complexity less than or equal to that represented in the training set.\relax }}{61}{table.caption.43}}
\newlabel{tab:generalization}{{4.2}{61}{\textit {Generalizability}. (Top) Shown are average F-scores for training and test sets resulting from a 5-fold cross-validation on a 5-song dataset (1000 generations). (Bottom) Results aggregated from 2 of the 5 cross-folds in which the holdout song is of simpler composition (\textit {Twinkle, Twinkle} and \textit {Over the Rainbow}). Results suggest that even with limited training, generalization is possible, particularly when generalizing to compositions with complexity less than or equal to that represented in the training set.\relax }{table.caption.43}{}}
\citation{gao2015octave}
\citation{pachet2011finite}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Binary Relational Constraints in Non-Homogeneous Markov Models}{63}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{63}{section.5.1}}
\citation{pesant2004regular}
\citation{papadopoulos2014avoiding}
\citation{papadopoulos2015exact}
\citation{papadopoulos2015exact}
\citation{barbieri2012markov}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Related Work}{64}{section.5.2}}
\citation{bodily2018floating}
\citation{roy2016enforcing}
\citation{collins2017computer}
\citation{pachet2017sampling}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}A DFA for Relational Constraints}{65}{section.5.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces $\ensuremath  {\unhbox \voidb@x \hbox {\sc  Relational Automaton}}$\relax }}{67}{algorithm.1}}
\newlabel{alg:matching}{{1}{67}{$\gbfs $\relax }{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces \textit  {A {\sc  Relational} automaton}. The result of Algorithm\nobreakspace  {}\ref  {alg:matching} on inputs $n=4$; $\mathcal  {M}=\{(X_1,X_4,\rho \}$ (where $\rho $ represents the set of rhyming word pairs); $I=\{$\textit  {Mary}, \textit  {Clay}$\}$; and $T$ derived from the non-zero transitions represented in the Markov model shown in Figure\nobreakspace  {}\ref  {fig:markov}.\relax }}{68}{figure.caption.44}}
\newlabel{fig:DFA}{{5.1}{68}{\textit {A {\sc Relational} automaton}. The result of Algorithm~\ref {alg:matching} on inputs $n=4$; $\mathcal {M}=\{(X_1,X_4,\rho \}$ (where $\rho $ represents the set of rhyming word pairs); $I=\{$\textit {Mary}, \textit {Clay}$\}$; and $T$ derived from the non-zero transitions represented in the Markov model shown in Figure~\ref {fig:markov}.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces \textit  {A Markov model.}\relax }}{69}{figure.caption.45}}
\newlabel{fig:markov}{{5.2}{69}{\textit {A Markov model.}\relax }{figure.caption.45}{}}
\citation{papadopoulos2015exact}
\citation{pachet2011finite}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Exact Sampling of Constrained Sequences}{70}{section.5.4}}
\citation{pachet2011finite}
\citation{pachet2011finite}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces $\ensuremath  {\unhbox \voidb@x \hbox {\sc  Regular NHMM}}$\relax }}{72}{algorithm.2}}
\newlabel{alg:nhmm}{{2}{72}{$\gbfsa $\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Structured Parallel Sequence Generation}{72}{section.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces \textit  {A ``state-sensitive'' pseudo-Markov model.} This is the model $M'$ built in Algorithm\nobreakspace  {}\ref  {alg:nhmm} given as inputs the automaton in Figure\nobreakspace  {}\ref  {fig:DFA}, the Markov model in Figure\nobreakspace  {}\ref  {fig:markov}, an empty unary constraint set, and a length $n=4$. This is a ``pseudo''-Markov model because, given this approach, probabilities must remain unnormalized for proper construction of the NHMM.\relax }}{73}{figure.caption.46}}
\newlabel{fig:ssMarkov}{{5.3}{73}{\textit {A ``state-sensitive'' pseudo-Markov model.} This is the model $M'$ built in Algorithm~\ref {alg:nhmm} given as inputs the automaton in Figure~\ref {fig:DFA}, the Markov model in Figure~\ref {fig:markov}, an empty unary constraint set, and a length $n=4$. This is a ``pseudo''-Markov model because, given this approach, probabilities must remain unnormalized for proper construction of the NHMM.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces \textit  {Amortized Sample Time By Sequences Generated}. Shown are average amortized sample times per sequence (belonging to the set $\{aa+b+\}$ of fixed length 100) when sampling using a NHMM (blue) and factor graph (orange). The NHMM has a longer build time but shorter sample time per sequence meaning that as the number of sequences increases, the NHMM has a lower amortized sample time than the factor graph.\relax }}{73}{figure.caption.47}}
\newlabel{fig:sampleTimeByCount}{{5.4}{73}{\textit {Amortized Sample Time By Sequences Generated}. Shown are average amortized sample times per sequence (belonging to the set $\{aa+b+\}$ of fixed length 100) when sampling using a NHMM (blue) and factor graph (orange). The NHMM has a longer build time but shorter sample time per sequence meaning that as the number of sequences increases, the NHMM has a lower amortized sample time than the factor graph.\relax }{figure.caption.47}{}}
\citation{bodily2018abstract}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces \textit  {Sample Time By Length}. Shown are average sample times for the NHMM (blue) and factor graph (orange) from sampling 100,000 sequences belonging to the set $\{aa+b+\}$. Both sample times increase linearly with the sequence length. Though the sample time per sequence is always lower for the NHMM, the NHMM build time also increases with sequence length resulting in a lower \emph  {amortized} sample time (dotted lines) for factor graphs as the sequence length increases.\relax }}{74}{figure.caption.48}}
\newlabel{fig:sampleTimeByLength}{{5.5}{74}{\textit {Sample Time By Length}. Shown are average sample times for the NHMM (blue) and factor graph (orange) from sampling 100,000 sequences belonging to the set $\{aa+b+\}$. Both sample times increase linearly with the sequence length. Though the sample time per sequence is always lower for the NHMM, the NHMM build time also increases with sequence length resulting in a lower \emph {amortized} sample time (dotted lines) for factor graphs as the sequence length increases.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces \textit  {Inferring Relational Constraints}. Relational constraint sets are inferred from real data using multiple-Smith-Waterman sequence alignment. Shown are the structural patterns inferred for the chord, pitch, rhythm, and lyric sequences in \emph  {Twinkle, Twinkle, Little Star}.\relax }}{75}{figure.caption.49}}
\newlabel{fig:structure}{{5.6}{75}{\textit {Inferring Relational Constraints}. Relational constraint sets are inferred from real data using multiple-Smith-Waterman sequence alignment. Shown are the structural patterns inferred for the chord, pitch, rhythm, and lyric sequences in \emph {Twinkle, Twinkle, Little Star}.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces \textit  {Horizontal and Vertical Structure}. Shown are four parallel sequences (chords, pitches, rhythms, and lyrics) that exhibit both \emph  {horizontal} structure---each fully satisfies Markovian constraints---and \emph  {vertical structure}---each fully satisfies binary relational constraints, frequently in the same sequence positions as with relational constraints in other sequences. Boxes of the same color are used to illustrate subsequences which position-by-position are constrained via binary relational constraints to be equivalent. Dark red boxes reflect binary relational rhyming constraints. Not labeled is the pattern of rhythmic repetition every 2 measures.\relax }}{75}{figure.caption.50}}
\newlabel{fig:song}{{5.7}{75}{\textit {Horizontal and Vertical Structure}. Shown are four parallel sequences (chords, pitches, rhythms, and lyrics) that exhibit both \emph {horizontal} structure---each fully satisfies Markovian constraints---and \emph {vertical structure}---each fully satisfies binary relational constraints, frequently in the same sequence positions as with relational constraints in other sequences. Boxes of the same color are used to illustrate subsequences which position-by-position are constrained via binary relational constraints to be equivalent. Dark red boxes reflect binary relational rhyming constraints. Not labeled is the pattern of rhythmic repetition every 2 measures.\relax }{figure.caption.50}{}}
\citation{Walker2004}
\citation{bodily2018floating}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Discussion and Conclusion}{77}{section.5.6}}
\citation{colton2012computational}
\citation{Boden2003TheEdition}
\citation{csikszentmihalyi1997flow}
\citation{silver2016mastering}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Computational Creativity: Theory and Application}{79}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{79}{section.6.1}}
\citation{colton2012computational}
\citation{colton2015stakeholder}
\citation{Ventura2017HowSystem}
\citation{Jordanous2014}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Characteristics of Creative Systems}{80}{section.6.2}}
\citation{Wiggins2006ASystems}
\citation{Ritchie2007}
\citation{Colton2008CreativitySystems}
\citation{Colton2011}
\citation{norton2013finding}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Characteristic \#1: Generative}{81}{subsection.6.2.1}}
\citation{Ventura2016}
\citation{Boden2003TheEdition}
\citation{kasof1995explaining}
\citation{Ritchie2007}
\citation{Ritchie2007}
\citation{Colton2008CreativitySystems}
\citation{Boden2003TheEdition}
\citation{Ventura2017HowSystem}
\citation{Ventura2016}
\citation{Ventura2017HowSystem}
\citation{Ventura2017HowSystem}
\citation{Lake2015}
\citation{Ventura2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Characteristic \#2: Knowledge Representation}{83}{subsection.6.2.2}}
\citation{Lake2015,Bodily2017ComputationalLearning}
\citation{Ventura2016,Ackerman2017TeachingCreativity}
\citation{Ventura2016}
\citation{Ackerman2017TeachingCreativity}
\citation{guckelsberger2017addressing}
\citation{norton2013finding}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Characteristic \#3: Intentionality}{84}{subsection.6.2.3}}
\citation{Colton2011}
\citation{csikszentmihalyi1997flow}
\citation{Koren2010WhichDefinitions}
\citation{Papadopoulos1999}
\citation{Koren2010WhichDefinitions}
\citation{Mothersill2004}
\citation{Koren2010WhichDefinitions}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Characteristic \#4: Aesthetic}{85}{subsection.6.2.4}}
\citation{Boden2003TheEdition}
\citation{Wiggins2006ASystems}
\citation{Ventura2017HowSystem}
\citation{Colton2011}
\citation{Jennings2010DevelopingIntelligence}
\citation{Bodily2018ExplainabilitySystems}
\citation{Colton2008CreativitySystems}
\citation{Boden2003TheEdition}
\citation{Hofstadter1980GodelBach}
\citation{birkhoff1933aesthetic}
\citation{shannon2001mathematical}
\citation{bodily2018ComparativeAnalysis}
\citation{Ritchie2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Characteristic \#5: Domain Knowledge}{86}{subsection.6.2.5}}
\citation{Ventura2016}
\citation{Lake2015}
\citation{perez2004three}
\citation{mumford2015man}
\citation{Ventura2016}
\citation{Colton2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Characteristic \#6: Autonomy}{87}{subsection.6.2.6}}
\citation{Jennings2010DevelopingIntelligence}
\citation{Ackerman2017TeachingCreativity}
\citation{Ventura2016}
\citation{Jennings2010DevelopingIntelligence}
\citation{Ackerman2017TeachingCreativity}
\citation{Ventura2016}
\citation{linkola2017aspects}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.7}Characteristic \#7: Self-Evaluative}{88}{subsection.6.2.7}}
\citation{perez2004three}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Pop*: An Applied Example}{89}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Pop*}{90}{subsection.6.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces \textit  {Pop* Overview}. A high-level depiction of the process by which Pop* composes new music. The system is inspired by social media posts that appeal to its aesthetic. This inspiration guides the training of generative models through a targeted subselection of available lyrics and lead sheets for training. Generated artefacts are output on condition that they pass an intention-driven self-evaluation.\relax }}{91}{figure.caption.51}}
\newlabel{fig:head}{{6.1}{91}{\textit {Pop* Overview}. A high-level depiction of the process by which Pop* composes new music. The system is inspired by social media posts that appeal to its aesthetic. This inspiration guides the training of generative models through a targeted subselection of available lyrics and lead sheets for training. Generated artefacts are output on condition that they pass an intention-driven self-evaluation.\relax }{figure.caption.51}{}}
\citation{steedman1984generative}
\citation{Jaques2016}
\citation{conklin1995multiple}
\citation{Jaques2016}
\citation{Nunes2014}
\citation{pachet2011finite-lengthConstraints}
\citation{Barbieri2012MarkovStyle}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Generative}{92}{subsection.6.3.2}}
\citation{pachet2011finite-lengthConstraints}
\citation{bodily2018relational}
\citation{bodily2018relational}
\citation{bodily2018relational}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces \textit  {NHMM for Binary Constraints}. Shown is a NHMM. Each column represents a position in the sequence to be generated. Transitions between columns are derived from the transition probabilities in the NHMM's underlying Markov model. This NHMM is built from a DFA that implements the binary constraint requiring the first and fourth positions of a sequence rhyme. The DFA adds automaton state sensitivity to the Markov states as detailed in \cite  {bodily2018relational}.\relax }}{94}{figure.caption.52}}
\newlabel{fig:graphical_model}{{6.2}{94}{\textit {NHMM for Binary Constraints}. Shown is a NHMM. Each column represents a position in the sequence to be generated. Transitions between columns are derived from the transition probabilities in the NHMM's underlying Markov model. This NHMM is built from a DFA that implements the binary constraint requiring the first and fourth positions of a sequence rhyme. The DFA adds automaton state sensitivity to the Markov states as detailed in \cite {bodily2018relational}.\relax }{figure.caption.52}{}}
\citation{Lake2015}
\citation{Bodily2017ComputationalLearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Knowledge Representation}{97}{subsection.6.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces \textit  {Graphical HBPL model}. This graphical model reflects the dependencies between subconcept models in Pop*'s HBPL model for lyrical music composition.\relax }}{98}{figure.caption.53}}
\newlabel{fig:graphical_model}{{6.3}{98}{\textit {Graphical HBPL model}. This graphical model reflects the dependencies between subconcept models in Pop*'s HBPL model for lyrical music composition.\relax }{figure.caption.53}{}}
\citation{Fast2016}
\citation{Ventura2017HowSystem}
\citation{Jennings2010DevelopingIntelligence}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Intentionality}{99}{subsection.6.3.4}}
\citation{Fast2016}
\citation{Fast2016}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces \textit  {Emotion topics}. Scores for this subset of the default topic set for Empath \citep  {Fast2016} are used to find tweets of interest that are emotionally charged.\relax }}{100}{table.caption.54}}
\newlabel{tab:empath_emotions}{{6.1}{100}{\textit {Emotion topics}. Scores for this subset of the default topic set for Empath \citep {Fast2016} are used to find tweets of interest that are emotionally charged.\relax }{table.caption.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}Aesthetic}{100}{subsection.6.3.5}}
\citation{Walker2004}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces \textit  {Learning Structure}. For each novel composition, Pop* chooses an existing song (in this case \textit  {Twinkle, Twinkle, Little Star}) after which to model structural patterns of repetition. Pop* uses a multi-Smith-Waterman alignment with a genetically trained scoring function to find structure in (from left to right) chords, pitch, rhythm, and lyrics.\relax }}{101}{figure.caption.55}}
\newlabel{fig:structure}{{6.4}{101}{\textit {Learning Structure}. For each novel composition, Pop* chooses an existing song (in this case \textit {Twinkle, Twinkle, Little Star}) after which to model structural patterns of repetition. Pop* uses a multi-Smith-Waterman alignment with a genetically trained scoring function to find structure in (from left to right) chords, pitch, rhythm, and lyrics.\relax }{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.6}Domain Knowledge}{101}{subsection.6.3.6}}
\citation{Witten1995}
\citation{bodily2018abstract}
\citation{bodily2018abstract}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.7}Autonomy}{104}{subsection.6.3.7}}
\citation{eigenfeldt2017distributed}
\citation{Ritchie2007}
\citation{Ritchie2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.8}Self-Evaluative}{105}{subsection.6.3.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces \textit  {External Artifact Representation}. Pop*'s creative process results essentially in a pop lead sheet (colored boxes highlight structural patterns of repetition). With regards to this composition, Pop* wrote: ``I spend a lot of time thinking and reading about \textbf  {being in love}, and I read this tweet from my friend Joel Alcaraz posted Tuesday, June 12, 2018 at 6:34 PM: `\textit  {It's interesting being in love with a person, I told Ashley my love for him is like dancing on the edge of a cliff always feeling a sense of trepidation before the grand leap into his world. But in the end no matter my fear I make a leap of faith. Is that what love is?}' It got me thinking about \textbf  {fear} and \textbf  {love} themes and I couldn't help but write this song: `\textit  {And I think I am just a lie `Cause when you find yourself behind And I think I am just a lie}'. At the beginning it was \textbf  {fear} and \textbf  {love}, however it really wound up with more of a \textbf  {deception} and \textbf  {negative} emotion theme. I hope that you like it.'' This composition rated highest overall in an external evaluation of 12 randomly selected Pop* compositions.\relax }}{106}{figure.caption.56}}
\newlabel{fig:cut_above}{{6.5}{106}{\textit {External Artifact Representation}. Pop*'s creative process results essentially in a pop lead sheet (colored boxes highlight structural patterns of repetition). With regards to this composition, Pop* wrote: ``I spend a lot of time thinking and reading about \textbf {being in love}, and I read this tweet from my friend Joel Alcaraz posted Tuesday, June 12, 2018 at 6:34 PM: `\textit {It's interesting being in love with a person, I told Ashley my love for him is like dancing on the edge of a cliff always feeling a sense of trepidation before the grand leap into his world. But in the end no matter my fear I make a leap of faith. Is that what love is?}' It got me thinking about \textbf {fear} and \textbf {love} themes and I couldn't help but write this song: `\textit {And I think I am just a lie `Cause when you find yourself behind And I think I am just a lie}'. At the beginning it was \textbf {fear} and \textbf {love}, however it really wound up with more of a \textbf {deception} and \textbf {negative} emotion theme. I hope that you like it.'' This composition rated highest overall in an external evaluation of 12 randomly selected Pop* compositions.\relax }{figure.caption.56}{}}
\citation{Ritchie2007}
\citation{kasof1995explaining,Boden2003TheEdition,Colton2008CreativitySystems}
\citation{Ventura2016}
\citation{Ventura2016}
\citation{Colton2011}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}External Evaluation of Creative Characteristics}{107}{section.6.4}}
\citation{Jordanous2012ACreative}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Evaluative Survey}{108}{subsection.6.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation Based on Artefacts}{108}{section*.57}}
\citation{likert1932technique}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation Based on Process}{110}{section*.58}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces \textit  {Results for Evaluation Based on Artefacts}. Shown are results based on the average ratings for each song. Columns correspond to survey questions 1 through 7. For each result is shown the average musicians' rating in italics followed by the average of all ratings. ``Best Song'' is the song with the highest overall rating score across all participants (shown in Figure\nobreakspace  {}\ref  {fig:cut_above}).\relax }}{111}{table.caption.59}}
\newlabel{tab:results}{{6.2}{111}{\textit {Results for Evaluation Based on Artefacts}. Shown are results based on the average ratings for each song. Columns correspond to survey questions 1 through 7. For each result is shown the average musicians' rating in italics followed by the average of all ratings. ``Best Song'' is the song with the highest overall rating score across all participants (shown in Figure~\ref {fig:cut_above}).\relax }{table.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Results}{111}{subsection.6.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces \textit  {Familiarity Bias}. Shown are the scores separated according to participants' answers to survey question 14 (familiarity with study designers). For each category is shown the average over all responses for each question as well as the highest individual average song scores for each of survey questions 1 through 7. With few exceptions the system was rated as more creative by those who are familiar with the system designers.\relax }}{112}{table.caption.60}}
\newlabel{tab:familiarity}{{6.3}{112}{\textit {Familiarity Bias}. Shown are the scores separated according to participants' answers to survey question 14 (familiarity with study designers). For each category is shown the average over all responses for each question as well as the highest individual average song scores for each of survey questions 1 through 7. With few exceptions the system was rated as more creative by those who are familiar with the system designers.\relax }{table.caption.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{Familiarity Bias}{112}{section*.61}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces \textit  {Results for Evaluation Based on Process}. Shown are average scores for survey questions 8 through 12, broken down by demographic.\relax }}{113}{table.caption.62}}
\newlabel{tab:results2}{{6.4}{113}{\textit {Results for Evaluation Based on Process}. Shown are average scores for survey questions 8 through 12, broken down by demographic.\relax }{table.caption.62}{}}
\@writefile{toc}{\contentsline {subsubsection}{Generative}{113}{section*.63}}
\@writefile{toc}{\contentsline {subsubsection}{Knowledge Representation}{114}{section*.64}}
\@writefile{toc}{\contentsline {subsubsection}{Intentionality}{114}{section*.65}}
\@writefile{toc}{\contentsline {subsubsection}{Aesthetic}{115}{section*.66}}
\@writefile{toc}{\contentsline {subsubsection}{Domain Knowledge}{115}{section*.67}}
\citation{mumford2015man}
\citation{mumford2015man}
\@writefile{toc}{\contentsline {subsubsection}{Autonomy}{117}{section*.68}}
\@writefile{toc}{\contentsline {subsubsection}{Self-Evaluative}{117}{section*.69}}
\@writefile{toc}{\contentsline {subsubsection}{Creativity}{118}{section*.70}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Discussion}{119}{section.6.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Future Work and Conclusion}{121}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Summary}{121}{section.7.1}}
\citation{Bodily2018ExplainabilitySystems}
\citation{*}
\bibstyle{plainnat}
\bibdata{bib}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Conclusion}{124}{section.7.2}}
\bibcite{abgaz2017characteristics}{{1}{2017}{{Abgaz et~al.}}{{Abgaz, Chaudhry, O\IeC {\textquoteright }Donoghue, Hurley, and Zhang}}}
\bibcite{ackerman2016algorithmic}{{2}{2016}{{Ackerman and Loker}}{{}}}
\bibcite{Ackerman2017TeachingCreativity}{{3}{2017}{{Ackerman et~al.}}{{Ackerman, Goel, Johnson, Jordanous, Le{\'{o}}n, P{\'{e}}rez~P{\'{e}}rez, Toivonen, and Ventura}}}
\bibcite{UCI}{{4}{}{{Asuncion and Newman}}{{}}}
\bibcite{BalasubramanianRel-grams:Text}{{5}{}{{Balasubramanian et~al.}}{{Balasubramanian, Soderland, and Etzioni}}}
\bibcite{barbieri2012markov}{{6}{2012{}}{{Barbieri et~al.}}{{Barbieri, Pachet, Roy, and Esposti}}}
\bibcite{Barbieri2012MarkovStyle}{{7}{2012{}}{{Barbieri et~al.}}{{Barbieri, Pachet, Roy, and Esposti}}}
\bibcite{BasAutomaticAnalysis}{{8}{}{{Bas et~al.}}{{Bas, Haas, Magal, Wiering, and Veltkamp}}}
\bibcite{bay2017ICCC}{{9}{2017}{{Bay et~al.}}{{Bay, Bodily, and Ventura}}}
\@writefile{toc}{\contentsline {chapter}{References}{126}{toclistings.4}}
\bibcite{benetos2013automatic}{{10}{2013}{{Benetos et~al.}}{{Benetos, Dixon, Giannoulis, Kirchhoff, and Klapuri}}}
\bibcite{birkhoff1933aesthetic}{{11}{1933}{{Birkhoff}}{{}}}
\bibcite{boden92}{{12}{1992}{{Boden}}{{}}}
\bibcite{Boden2003TheEdition}{{13}{2003}{{Boden}}{{}}}
\bibcite{bodily2017Mume}{{14}{2017}{{Bodily and Ventura}}{{}}}
\bibcite{bodily2018abstract}{{15}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{bodily2018floating}{{16}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{bodily2018relational}{{17}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{bodily2017ICCC}{{18}{2017{}}{{Bodily et~al.}}{{Bodily, Bay, and Ventura}}}
\bibcite{Bodily2017ComputationalLearning}{{19}{2017{}}{{Bodily et~al.}}{{Bodily, Bay, and Ventura}}}
\bibcite{Bodily2018ExplainabilitySystems}{{20}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{Bodily2018MusicalFuture}{{21}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{bodily2018ComparativeAnalysis}{{22}{2018{}}{{Bodily and Ventura}}{{}}}
\bibcite{chuan2011generating}{{23}{2011}{{Chuan and Chew}}{{}}}
\bibcite{collins2017computer}{{24}{2017}{{Collins and Laney}}{{}}}
\bibcite{collins2010comparative}{{25}{2010}{{Collins et~al.}}{{Collins, Thurlow, Laney, Willis, and Garthwaite}}}
\bibcite{Colton2008CreativitySystems}{{26}{2008{}}{{Colton}}{{}}}
\bibcite{colton2008creativity}{{27}{2008{}}{{Colton}}{{}}}
\bibcite{colton2012computational}{{28}{2012}{{Colton and Wiggins}}{{}}}
\bibcite{ColtonExperimentsBrowsing}{{29}{2010}{{Colton et~al.}}{{Colton, Gow, Torres, and Cairns}}}
\bibcite{Colton2011}{{30}{2011}{{Colton et~al.}}{{Colton, Pease, and Charnley}}}
\bibcite{colton2015stakeholder}{{31}{2015}{{Colton et~al.}}{{Colton, Pease, Corneli, Cook, Hepworth, and Ventura}}}
\bibcite{conklin1995multiple}{{32}{1995}{{Conklin and Witten}}{{}}}
\bibcite{cook2015generating}{{33}{2015}{{Cook and Colton}}{{}}}
\bibcite{cope1989experiments}{{34}{1989}{{Cope}}{{}}}
\bibcite{csikszentmihalyi1997flow}{{35}{1997}{{Csikszentmihalyi}}{{}}}
\bibcite{davies2009385+}{{36}{2009}{{Davies}}{{}}}
\bibcite{dayhoff197822}{{37}{1978}{{Dayhoff et~al.}}{{Dayhoff, Schwartz, and Orcutt}}}
\bibcite{dixon2010probabilistic}{{38}{2010}{{Dixon et~al.}}{{Dixon, Mauch, and Anglade}}}
\bibcite{eigenfeldt2017distributed}{{39}{2017}{{Eigenfeldt et~al.}}{{Eigenfeldt, Bown, Brown, and Gifford}}}
\bibcite{englemann1974distar}{{40}{1974}{{Englemann and Bruner}}{{}}}
\bibcite{FastEmpath:Text}{{41}{}{{Fast et~al.}}{{Fast, Chen, and Bernstein}}}
\bibcite{Fast2016}{{42}{2016{}}{{Fast et~al.}}{{Fast, Chen, and Bernstein}}}
\bibcite{fast2016empath}{{43}{2016{}}{{Fast et~al.}}{{Fast, Chen, and Bernstein}}}
\bibcite{gao2015octave}{{44}{2015}{{Gao and Li}}{{}}}
\bibcite{Gatys2015AStyle}{{45}{2015}{{Gatys et~al.}}{{Gatys, Ecker, and Bethge}}}
\bibcite{gonccalo2015tra}{{46}{2015}{{Gon{\c {c}}alo~Oliveira}}{{}}}
\bibcite{guckelsberger2017addressing}{{47}{2017}{{Guckelsberger et~al.}}{{Guckelsberger, Salge, and Colton}}}
\bibcite{heath2016creating}{{48}{2016}{{Heath and Ventura}}{{}}}
\bibcite{hedges2016improving}{{49}{2016}{{Hedges et~al.}}{{Hedges, Wiggins, et~al.}}}
\bibcite{henikoff1992amino}{{50}{1992}{{Henikoff and Henikoff}}{{}}}
\bibcite{hirjee2010using}{{51}{2010}{{Hirjee and Brown}}{{}}}
\bibcite{hofstadter1980godel}{{52}{1980{}}{{Hofstadter}}{{}}}
\bibcite{Hofstadter1980GodelBach}{{53}{1980{}}{{Hofstadter}}{{}}}
\bibcite{Hu2003AKEY-PROFILES}{{54}{2003}{{Hu and Saul}}{{}}}
\bibcite{HuAClassification}{{55}{}{{Hu et~al.}}{{Hu, Choi, and Downie}}}
\bibcite{hyer2001}{{56}{2001}{{Hyer}}{{}}}
\bibcite{jalongo1997using}{{57}{1997}{{Jalongo and Ribblett}}{{}}}
\bibcite{Jaques2016}{{58}{2016}{{Jaques et~al.}}{{Jaques, Gu, Turner, and Eck}}}
\bibcite{Jennings2010DevelopingIntelligence}{{59}{2010}{{Jennings}}{{}}}
\bibcite{Jordanous2012ACreative}{{60}{2012}{{Jordanous}}{{}}}
\bibcite{Jordanous2014}{{61}{2014}{{Jordanous}}{{}}}
\bibcite{Kaliakatsos-PapakostasAnBlending}{{62}{}{{Kaliakatsos-Papakostas et~al.}}{{Kaliakatsos-Papakostas, Confalonieri, Corneli, Zacharakis, and Cambouropoulos}}}
\bibcite{Kaliakatsos-PapakostasAnBlendingb}{{63}{}{{Kaliakatsos-Papakostas et~al.}}{{Kaliakatsos-Papakostas, Confalonieri, Corneli, Zacharakis, and Cambouropoulos}}}
\bibcite{OZ}{{64}{1990}{{Kantrowitz}}{{}}}
\bibcite{kasof1995explaining}{{65}{1995}{{Kasof}}{{}}}
\bibcite{kazakcci2016digits}{{66}{2016}{{Kazak{\c {c}}{\i } et~al.}}{{Kazak{\c {c}}{\i }, Mehdi, and K{\'e}gl}}}
\bibcite{kolb1996read}{{67}{1996}{{Kolb}}{{}}}
\bibcite{Koren2010WhichDefinitions}{{68}{2010}{{Koren}}{{}}}
\bibcite{lake2014thesis}{{69}{2014}{{Lake}}{{}}}
\bibcite{Lake2015}{{70}{2015{}}{{Lake et~al.}}{{Lake, Salakhutdinov, and Tenenbaum}}}
\bibcite{lake2015human}{{71}{2015{}}{{Lake et~al.}}{{Lake, Salakhutdinov, and Tenenbaum}}}
\bibcite{lattner2015pseudo}{{72}{2015{}}{{Lattner et~al.}}{{Lattner, Chac{\'o}n, and Grachten}}}
\bibcite{lattner2015probabilistic}{{73}{2015{}}{{Lattner et~al.}}{{Lattner, Grachten, Agres, and Chac{\'o}n}}}
\bibcite{lecun2015deep}{{74}{2015}{{LeCun et~al.}}{{LeCun, Bengio, and Hinton}}}
\bibcite{likert1932technique}{{75}{1932}{{Likert}}{{}}}
\bibcite{linkola2017aspects}{{76}{2017}{{Linkola et~al.}}{{Linkola, Kantosalo, M{\"a}nnist{\"o}, and Toivonen}}}
\bibcite{Loughran2017MyProject}{{77}{2017}{{Loughran et~al.}}{{Loughran, Neill, and Loughran}}}
\bibcite{lyu04}{{78}{2004}{{Lyu et~al.}}{{Lyu, Rockmore, and Farid}}}
\bibcite{Manning2014}{{79}{2014}{{Manning et~al.}}{{Manning, Surdeanu, Bauer, Finkel, Bethard, and McClosky}}}
\bibcite{meredith2002algorithms}{{80}{2002}{{Meredith et~al.}}{{Meredith, Lemstr{\"o}m, and Wiggins}}}
\bibcite{meyer2008emotion}{{81}{2008}{{Meyer}}{{}}}
\bibcite{mikolov2013distributed}{{82}{2013}{{Mikolov et~al.}}{{Mikolov, Sutskever, Chen, Corrado, and Dean}}}
\bibcite{monteith2010automatic}{{83}{2010}{{Monteith et~al.}}{{Monteith, Martinez, and Ventura}}}
\bibcite{monteith2012automatic}{{84}{2012}{{Monteith et~al.}}{{Monteith, Martinez, and Ventura}}}
\bibcite{Morris2012SoupChef}{{85}{2012{}}{{Morris et~al.}}{{Morris, Burton, Bodily, and Ventura}}}
\bibcite{Morris2012SoupChefb}{{86}{2012{}}{{Morris et~al.}}{{Morris, Burton, Bodily, and Ventura}}}
\bibcite{morris2012soup}{{87}{2012{}}{{Morris et~al.}}{{Morris, Burton, Bodily, and Ventura}}}
\bibcite{Mothersill2004}{{88}{2004}{{Mothersill}}{{}}}
\bibcite{mumford2015man}{{89}{2015}{{Mumford and Ventura}}{{}}}
\bibcite{needleman1970general}{{90}{1970}{{Needleman and Wunsch}}{{}}}
\bibcite{norton2013finding}{{91}{2013}{{Norton et~al.}}{{Norton, Heath, and Ventura}}}
\bibcite{Nunes2014}{{92}{2014}{{Nunes et~al.}}{{Nunes, Ordanini, and Valsesia}}}
\bibcite{pachet1991representing}{{93}{1991}{{Pachet}}{{}}}
\bibcite{pachet2014imitative}{{94}{2014}{{Pachet and Roy}}{{}}}
\bibcite{pachet2011finite}{{95}{2011}{{Pachet et~al.}}{{Pachet, Roy, Barbieri, and Paris}}}
\bibcite{pachet2017sampling}{{96}{2017}{{Pachet et~al.}}{{Pachet, Paris, Papadopoulos, and Roy}}}
\bibcite{paiement2005chord}{{97}{2005}{{Paiement et~al.}}{{Paiement, Eck, and Bengio}}}
\bibcite{papadopoulos2014avoiding}{{98}{2014}{{Papadopoulos et~al.}}{{Papadopoulos, Roy, and Pachet}}}
\bibcite{papadopoulos2015exact}{{99}{2015}{{Papadopoulos et~al.}}{{Papadopoulos, Pachet, Roy, and Sakellariou}}}
\bibcite{papadopoulos2016assisted}{{100}{2016}{{Papadopoulos et~al.}}{{Papadopoulos, Roy, and Pachet}}}
\bibcite{Papadopoulos1999}{{101}{1999{}}{{Papadopoulos and Wiggins}}{{}}}
\bibcite{papadopoulos1999ai}{{102}{1999{}}{{Papadopoulos and Wiggins}}{{}}}
\bibcite{paris2013natural}{{103}{2013}{{Paris et~al.}}{{Paris, Swartout, and Mann}}}
\bibcite{pasiali2004use}{{104}{2004}{{Pasiali}}{{}}}
\bibcite{PearceMethodsMusic}{{105}{}{{Pearce et~al.}}{{Pearce, Conklin, and Wiggins}}}
\bibcite{perez2017mdds}{{106}{2017}{{Perez and R{\'e}gin}}{{}}}
\bibcite{perez2015computer}{{107}{2015}{{P{\'e}rez~y P{\'e}rez}}{{}}}
\bibcite{perez2004three}{{108}{2004}{{P{\'e}rez~y P{\'e}rez and Sharples}}{{}}}
\bibcite{pesant2004regular}{{109}{2004}{{Pesant}}{{}}}
\bibcite{ramakrishnan2009automatic}{{110}{2009}{{Ramakrishnan~A et~al.}}{{Ramakrishnan~A, Kuppan, and Devi}}}
\bibcite{Raphael2004FunctionalModels}{{111}{2004}{{Raphael and Stoddard}}{{}}}
\bibcite{Raschka2014MusicMood:Learning}{{112}{2014}{{Raschka}}{{}}}
\bibcite{Revuz1992MinimisationTime}{{113}{1992}{{Revuz}}{{}}}
\bibcite{Ritchie2007}{{114}{2007{}}{{Ritchie}}{{}}}
\bibcite{ritchie07}{{115}{2007{}}{{Ritchie}}{{}}}
\bibcite{robb2008randomized}{{116}{2008}{{Robb et~al.}}{{Robb, Clair, Watanabe, Monahan, Azzouz, Stouffer, Ebberts, Darsie, Whitmer, Walker, et~al.}}}
\bibcite{roy2013enforcing}{{117}{2013}{{Roy and Pachet}}{{}}}
\bibcite{roy2016enforcing}{{118}{2016}{{Roy et~al.}}{{Roy, Perez, R{\'e}gin, Papadopoulos, Pachet, and Marchini}}}
\bibcite{Ruch07}{{119}{2007}{{Ruch}}{{}}}
\bibcite{scirea2015smug}{{120}{2015}{{Scirea et~al.}}{{Scirea, Barros, Shaker, and Togelius}}}
\bibcite{shannon2001mathematical}{{121}{2001}{{Shannon}}{{}}}
\bibcite{Sharma2016SentimentsSentiWordNet}{{122}{2016}{{Sharma et~al.}}{{Sharma, Agarwal, Dhir, and Sikka}}}
\bibcite{ShenoyKeySignals}{{123}{}{{Shenoy et~al.}}{{Shenoy, Mohapatra, and {Ye Wang}}}}
\bibcite{Shukla2017ReviewMusic}{{124}{2017}{{Shukla et~al.}}{{Shukla, Khanna, and Agrawal}}}
\bibcite{silver2016mastering}{{125}{2016}{{Silver et~al.}}{{Silver, Huang, Maddison, Guez, Sifre, Van Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, et~al.}}}
\bibcite{smith1981identification}{{126}{1981}{{Smith and Waterman}}{{}}}
\bibcite{steedman1984generative}{{127}{1984}{{Steedman}}{{}}}
\bibcite{toivanen2013automatical}{{128}{2013}{{Toivanen et~al.}}{{Toivanen, Toivonen, Valitutti, et~al.}}}
\bibcite{towell1999motivating}{{129}{1999}{{Towell}}{{}}}
\bibcite{TrimmerEmotionalProsody}{{130}{}{{Trimmer and Cuddy}}{{}}}
\bibcite{van2016wavenet}{{131}{2016}{{van~den Oord et~al.}}{{van~den Oord, Dieleman, Zen, Simonyan, Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu}}}
\bibcite{veale07}{{132}{2007}{{Veale and Hao}}{{}}}
\bibcite{Ventura2016}{{133}{2016}{{Ventura}}{{}}}
\bibcite{Ventura2017HowSystem}{{134}{2017}{{Ventura}}{{}}}
\bibcite{volioti2016mapping}{{135}{2016}{{Volioti et~al.}}{{Volioti, Hadjidimitriou, Manitsaris, Hadjileontiadis, Charisis, and Manitsaris}}}
\bibcite{Vos1996AModel}{{136}{1996}{{Vos and Van~Geenen}}{{}}}
\bibcite{Walker2004}{{137}{2004}{{Walker et~al.}}{{Walker, Lamere, Kwok, Raj, Singh, Gouvea, Wolf, and Woelfel}}}
\bibcite{widmer2017getting}{{138}{2017}{{Widmer}}{{}}}
\bibcite{Wiggins2006ASystems}{{139}{2006}{{Wiggins}}{{}}}
\bibcite{WigginsIDyOT:Information}{{140}{}{{Wiggins et~al.}}{{Wiggins, Forth, Wiggins, and Forth}}}
\bibcite{Witten1995}{{141}{1995}{{Witten and Conklin}}{{}}}
\bibcite{Woods81}{{142}{1981}{{Woods}}{{}}}
\bibcite{XuAutomaticMusic}{{143}{}{{Xu et~al.}}{{Xu, Maddage, and Kankanhalli}}}
\bibcite{YadollahiCurrentMining}{{144}{}{{Yadollahi et~al.}}{{Yadollahi, Shahraki, and Zaiane}}}
